"""
–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø LLM —Å–µ—Å—Å–∏—è —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
"""

import re
import json
import logging
from typing import Dict, List, Optional, Tuple
from .openrouter_client import MessageContext
from .prompt_manager import PromptManager
from .config import load_config

logger = logging.getLogger(__name__)


class InterpretationStage:
    """–≠—Ç–∞–ø—ã –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏"""
    SYSTEM = "system"
    SPREAD_CONTEXT = "spread_context" 
    PSYCHOLOGICAL_ANALYSIS = "psychological_analysis"
    CONTEXT_ANALYSIS = "context_analysis"
    SYNTHESIS = "synthesis"
    FINAL_RESPONSE = "final_response"


class FixedLLMSession:
    """
    –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø LLM —Å–µ—Å—Å–∏—è —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π:
    - –í—Å–µ –ø—Ä–æ–º–ø—Ç—ã –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –≤ –µ–¥–∏–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
    - –û–î–ò–ù —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å –≤ –∫–æ–Ω—Ü–µ
    - LLM –≤–∏–¥–∏—Ç –≤—Å—é –∏—Å—Ç–æ—Ä–∏—é –≤–∫–ª—é—á–∞—è –≤—Å–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
    """
    
    def __init__(self, prompt_manager: PromptManager, model_name: str = None):
        self.prompt_manager = prompt_manager
        self.config = load_config()
        
        # –°–æ–∑–¥–∞–µ–º MessageContext —Å mode=2 (–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ!)
        self.context = MessageContext(task_prompt=None)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∏–ª–∏ –±–µ—Ä–µ–º –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        if model_name is None:
            model_name = self.config.get("model_name", "deepseek/deepseek-chat-v3-0324:free")
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
        self.model_name = model_name
        self.api_key = self.config.get("openrouter_api_key")
        self.max_tokens = self.config.get("max_response_tokens", 8000)
        self.temperature = self.config.get("temperature", 0.3)
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ —Å–µ—Å—Å–∏–∏
        self.current_stage = None
        self.user_data = {}
        self.spread_data = {}
        self.generated_questions = []
        
    def setup_spread(self, spread_type: str, selected_cards: List[Dict], 
                    spread_config: Dict, user_name: str, user_age: int, 
                    magic_number: int):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Ä–∞—Å–∫–ª–∞–¥–∞"""
        self.spread_data = {
            'spread_type': spread_type,
            'selected_cards': selected_cards,
            'spread_config': spread_config,
            'user_name': user_name,
            'user_age': user_age,
            'magic_number': magic_number
        }
        
        self.user_data = {
            'name': user_name,
            'age': user_age,
            'magic_number': magic_number
        }
    
    def add_spread_context(self, spread_type: str):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞—Å–∫–ª–∞–¥–∞ –≤ —Å–µ—Å—Å–∏—é"""
        context_prompt = self.prompt_manager.get_spread_context_prompt(spread_type)
        self.context.add_user_message(context_prompt)
        self.current_stage = InterpretationStage.SPREAD_CONTEXT
        logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞—Å–∫–ª–∞–¥–∞: {spread_type}")
    
    def build_complete_context(self, preliminary_answers: List[str], 
                              additional_answers: List[str] = None) -> bool:
        """
        –ö–õ–Æ–ß–ï–í–û–ô –ú–ï–¢–û–î: –°—Ç—Ä–æ–∏—Ç –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ –í–°–ï–ú–ò –ø—Ä–æ–º–ø—Ç–∞–º–∏
        –≠—Ç–æ –∏ –µ—Å—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ LLM_algorithm.md!
        """
        try:
            # 1. –°–∏—Å—Ç–µ–º–Ω–∞—è –ø–µ—Ä—Å–æ–Ω–∞ (01_system_persona.md)
            system_prompt = self.prompt_manager.get_system_persona(
                name=self.user_data['name'],
                age=self.user_data['age']
            )
            self.context = MessageContext(task_prompt=system_prompt)
            logger.info("1Ô∏è‚É£ –î–æ–±–∞–≤–ª–µ–Ω —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç")
            
            # 2. –ö–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞—Å–∫–ª–∞–¥–∞ (02_*_context.md)
            spread_type = self.spread_data.get('spread_type', '')
            spread_prompt = self.prompt_manager.get_spread_context(
                spread_type=spread_type,
                selected_cards=self.spread_data['selected_cards'],
                positions=self.spread_data['spread_config'].get('card_meanings', [])
            )
            self.context.add_user_message(spread_prompt)
            logger.info(f"2Ô∏è‚É£ –î–æ–±–∞–≤–ª–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞—Å–∫–ª–∞–¥–∞: {spread_type}")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
            if preliminary_answers:
                answers_text = "\\n".join([f"{i+1}. {answer}" for i, answer in enumerate(preliminary_answers)])
                self.context.add_user_message(f"–ü–†–ï–î–í–ê–†–ò–¢–ï–õ–¨–ù–´–ï –û–¢–í–ï–¢–´ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:\\n{answers_text}")
                logger.info("üìù –î–æ–±–∞–≤–ª–µ–Ω—ã –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã")
            
            # 3. –ü—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∏ –≤–æ–ø—Ä–æ—Å—ã (03_psychological_analysis_questions.md) 
            analysis_prompt = self.prompt_manager.get_psychological_analysis_prompt(
                user_answers=preliminary_answers or []
            )
            self.context.add_user_message(analysis_prompt)
            logger.info("3Ô∏è‚É£ –î–æ–±–∞–≤–ª–µ–Ω –ø—Ä–æ–º–ø—Ç –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –µ—Å–ª–∏ –µ—Å—Ç—å
            if additional_answers:
                additional_text = "\\n".join([f"{i+1}. {answer}" for i, answer in enumerate(additional_answers)])
                self.context.add_user_message(f"–î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –û–¢–í–ï–¢–´ –ù–ê –£–¢–û–ß–ù–Ø–Æ–©–ò–ï –í–û–ü–†–û–°–´:\\n{additional_text}")
                logger.info("üìù –î–æ–±–∞–≤–ª–µ–Ω—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã")
            
            # 4. –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –∫–∞—Ä—Ç (04_context_analysis_and_card_interpretation.md)
            context_analysis_prompt = self.prompt_manager.get_context_analysis_prompt()
            self.context.add_user_message(context_analysis_prompt)
            logger.info("4Ô∏è‚É£ –î–æ–±–∞–≤–ª–µ–Ω –ø—Ä–æ–º–ø—Ç –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞")
            
            # 5. –ì–ª—É–±–æ–∫–∏–π —Å–∏–Ω—Ç–µ–∑ (05_deep_synthesis_and_story_planning.md)
            synthesis_prompt = self.prompt_manager.get_synthesis_prompt()
            self.context.add_user_message(synthesis_prompt)
            logger.info("5Ô∏è‚É£ –î–æ–±–∞–≤–ª–µ–Ω –ø—Ä–æ–º–ø—Ç —Å–∏–Ω—Ç–µ–∑–∞")
            
            # 6. –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç (06_final_user_response.md)
            final_prompt = self.prompt_manager.get_final_response_prompt()
            self.context.add_user_message(final_prompt)
            logger.info("6Ô∏è‚É£ –î–æ–±–∞–≤–ª–µ–Ω –ø—Ä–æ–º–ø—Ç —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞")
            
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {e}")
            return False
    
    async def generate_complete_interpretation(self) -> Optional[str]:
        """
        –ï–î–ò–ù–°–¢–í–ï–ù–ù–´–ô –∑–∞–ø—Ä–æ—Å –∫ LLM —Å –ø–æ–ª–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º!
        –≠—Ç–æ –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è - LLM –≤–∏–¥–∏—Ç –í–°–ï –ø—Ä–æ–º–ø—Ç—ã –≤–∫–ª—é—á–∞—è —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏!
        """
        try:
            messages = self.context.get_message_history()
            
            # –õ–æ–≥–∏—Ä—É–µ–º –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ 
            logger.info(f"–û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å —Å {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –∫ –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç
            full_context = "\\n".join([msg['content'][0]['text'] for msg in messages])
            has_brevity = "–¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ –∫ –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏" in full_context
            logger.info(f"–¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ –∫ –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ: {has_brevity}")
            
            from .openrouter_client import send_request
            response = await send_request(
                messages=messages,
                model=self.model_name,
                api_key=self.api_key,
                max_tokens=self.max_tokens,
                temperature=self.temperature
            )
            
            self.current_stage = InterpretationStage.FINAL_RESPONSE
            logger.info("üéØ –ü–æ–ª–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞ –∑–∞ –û–î–ò–ù –∑–∞–ø—Ä–æ—Å!")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é
            cleaned_response = self._extract_final_interpretation(response)
            return cleaned_response
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–ª–Ω–æ–π –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏: {e}")
            return None
    
    def _extract_final_interpretation(self, response: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—É—é –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM"""
        try:
            # –°–ø–æ—Å–æ–± 1: –ò—â–µ–º –º–∞—Ä–∫–µ—Ä—ã [INTERPRETATION_START] –∏ [INTERPRETATION_END]
            interpretation_match = re.search(r'\\[INTERPRETATION_START\\](.*?)\\[INTERPRETATION_END\\]', 
                                           response, re.DOTALL | re.IGNORECASE)
            if interpretation_match:
                cleaned = interpretation_match.group(1).strip()
                logger.info("‚úÖ –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∞ –ø–æ –º–∞—Ä–∫–µ—Ä–∞–º")
                return cleaned
            
            # –°–ø–æ—Å–æ–± 2: –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –±–ª–æ–∫ –ø–æ—Å–ª–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
            lines = response.split('\\n')
            interpretation_lines = []
            capturing = False
            
            for line in lines:
                if 'INTERPRETATION_START' in line or capturing:
                    capturing = True
                    if 'INTERPRETATION_END' in line:
                        break
                    interpretation_lines.append(line)
            
            if interpretation_lines:
                result = '\\n'.join(interpretation_lines).strip()
                # –û—á–∏—â–∞–µ–º –æ—Ç –≤–æ–∑–º–æ–∂–Ω—ã—Ö –º–∞—Ä–∫–µ—Ä–æ–≤
                result = re.sub(r'\\[INTERPRETATION_(START|END)\\]', '', result).strip()
                logger.info("‚úÖ –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∞ –ø–æ –±–ª–æ–∫–∞–º")
                return result
            
            # –°–ø–æ—Å–æ–± 3: –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 1000-2000 —Å–∏–º–≤–æ–ª–æ–≤ –∫–∞–∫ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é
            if len(response) > 1000:
                result = response[-2000:].strip()
                logger.info("‚ö†Ô∏è –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –≤–∑—è—Ç–∞ –∫–∞–∫ –ø–æ—Å–ª–µ–¥–Ω–∏–π –±–ª–æ–∫")
                return result
            
            # –°–ø–æ—Å–æ–± 4: –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–µ—Å—å –æ—Ç–≤–µ—Ç
            logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–¥–µ–ª–∏—Ç—å –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç")
            return response.strip()
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏: {e}")
            return response.strip()
    
    def get_context_debug_info(self) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ"""
        messages = self.context.get_message_history()
        full_context = "\\n".join([msg['content'][0]['text'] for msg in messages])
        
        return {
            'message_count': len(messages),
            'total_length': len(full_context),
            'has_brevity_instruction': '–¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ –∫ –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏' in full_context,
            'has_system_persona': '01_system_persona' in full_context,
            'has_spread_context': '02_' in full_context and '_context' in full_context,
            'context_preview': full_context[:500] + '...' if len(full_context) > 500 else full_context
        }